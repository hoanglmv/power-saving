{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "# # (train.ipynb) - Mô hình dự đoán KPI\n",
    "#\n",
    "# **Mục tiêu:** Huấn luyện một mô hình AI (LSTM) để dự đoán dữ liệu KPI\n",
    "# của 1 ngày tiếp theo (96 mẫu 15 phút) dựa trên dữ liệu của 7 ngày\n",
    "# trước đó (672 mẫu 15 phút), áp dụng cho từng `cell_name`.\n",
    "#\n",
    "# **Pipeline:**\n",
    "# 1. Tải dữ liệu đã xử lý (`.parquet`).\n",
    "# 2. Định nghĩa các hằng số (7 ngày vào, 1 ngày ra).\n",
    "# 3. Chia dữ liệu Train/Validation/Test theo **thời gian (chronological)**.\n",
    "# 4. Chuẩn hóa (Scale) dữ liệu.\n",
    "# 5. Tạo các \"cửa sổ\" (windows) dữ liệu 7 ngày -> 1 ngày.\n",
    "# 6. Xây dựng mô hình LSTM (Seq2Seq).\n",
    "# 7. Huấn luyện và đánh giá mô hình.\n",
    "\n",
    "# %%\n",
    "# --- Cell 1: Tải các thư viện ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cấu hình hiển thị\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "744ac6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tải file 'kpi_processed.csv' thành công.\n",
      "Dữ liệu có 313186 hàng, kéo dài từ 2025-10-11 00:00:00 đến 2025-11-10 23:45:00.\n",
      "\n",
      "Thông tin dữ liệu (df.info()):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 313186 entries, 2025-10-11 00:00:00 to 2025-11-10 23:00:00\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   enodeb                  313186 non-null  object \n",
      " 1   cell_name               313186 non-null  object \n",
      " 2   ps_traffic_mb           313168 non-null  float64\n",
      " 3   avg_rrc_connected_user  313186 non-null  float64\n",
      " 4   prb_dl_used             312997 non-null  float64\n",
      " 5   prb_dl_available_total  312997 non-null  float64\n",
      " 6   prb_utilization         313186 non-null  float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 19.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- Cell 2 (train.ipynb - SỬA LỖI CHO CSV): Tải dữ liệu đã xử lý ---\n",
    "\n",
    "file_name = 'kpi_processed.csv' # <-- Đã đổi tên file\n",
    "\n",
    "try:\n",
    "    # *** THAY ĐỔI QUAN TRỌNG ***\n",
    "    # Chúng ta dùng pd.read_csv và thêm 2 tham số:\n",
    "    # 1. index_col=0: Báo cho Pandas rằng cột đầu tiên (cột 0) là index.\n",
    "    # 2. parse_dates=True: Báo cho Pandas chuyển đổi index đó thành Datetime.\n",
    "    \n",
    "    df = pd.read_csv(file_name, index_col=0, parse_dates=True)\n",
    "    \n",
    "    print(f\"Tải file '{file_name}' thành công.\")\n",
    "    print(f\"Dữ liệu có {len(df)} hàng, kéo dài từ {df.index.min()} đến {df.index.max()}.\")\n",
    "    print(\"\\nThông tin dữ liệu (df.info()):\")\n",
    "    # Kiểm tra kỹ: Index phải là 'DatetimeIndex'\n",
    "    df.info() \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"LỖI: Không thể tải file '{file_name}'.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f3eeffa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự đoán 5 features: ['ps_traffic_mb', 'avg_rrc_connected_user', 'prb_dl_used', 'prb_dl_available_total', 'prb_utilization']\n",
      "Đang xử lý: Đảm bảo dữ liệu 15 phút đầy đủ cho mỗi cell...\n",
      "Dữ liệu trước khi xử lý trùng lặp: 313186 hàng\n",
      "Dữ liệu sau khi xử lý trùng lặp (groupby.mean): 303370 hàng\n",
      "Dữ liệu gốc có 313186 hàng.\n",
      "Dữ liệu đã điền đầy đủ (sau reindex) có 321408 hàng.\n",
      "Hoàn tất xử lý.\n",
      "\n",
      "5 dòng đầu của dữ liệu đã xử lý đầy đủ:\n",
      "                    cell_name  ps_traffic_mb  avg_rrc_connected_user  \\\n",
      "timestamp                                                              \n",
      "2025-10-11 00:00:00  EnodebA3         161.14                8.527778   \n",
      "2025-10-11 00:15:00  EnodebA3           0.00                0.000000   \n",
      "2025-10-11 00:30:00  EnodebA3           0.00                0.000000   \n",
      "2025-10-11 00:45:00  EnodebA3           0.00                0.000000   \n",
      "2025-10-11 01:00:00  EnodebA3         231.61                7.777778   \n",
      "\n",
      "                     prb_dl_used  prb_dl_available_total  prb_utilization  \n",
      "timestamp                                                                  \n",
      "2025-10-11 00:00:00         67.5                    15.0            450.0  \n",
      "2025-10-11 00:15:00          0.0                     0.0              0.0  \n",
      "2025-10-11 00:30:00          0.0                     0.0              0.0  \n",
      "2025-10-11 00:45:00          0.0                     0.0              0.0  \n",
      "2025-10-11 01:00:00         67.5                    15.0            450.0  \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- Cell 3 (SỬA LỖI LẦN 2): Xử lý dữ liệu (Quan trọng!) ---\n",
    "# Mục tiêu: Đảm bảo MỌI cell_name đều có đầy đủ 15 phút, không bị ngắt quãng.\n",
    "# Nếu thiếu, chúng ta sẽ lấp đầy bằng 0.\n",
    "\n",
    "if 'df' in locals():\n",
    "    # Xác định các cột KPI để dự đoán\n",
    "    FEATURE_COLS = ['ps_traffic_mb', 'avg_rrc_connected_user', 'prb_dl_used', 'prb_dl_available_total', 'prb_utilization']\n",
    "    N_FEATURES = len(FEATURE_COLS)\n",
    "\n",
    "    print(f\"Dự đoán {N_FEATURES} features: {FEATURE_COLS}\")\n",
    "\n",
    "    # Tạo ra một DataFrame đầy đủ cho MỌI cell\n",
    "    print(\"Đang xử lý: Đảm bảo dữ liệu 15 phút đầy đủ cho mỗi cell...\")\n",
    "    \n",
    "    # Lấy tất cả các cell độc nhất\n",
    "    all_cells = df['cell_name'].unique()\n",
    "    \n",
    "    # Tạo ra một index thời gian 15 phút đầy đủ từ đầu đến cuối\n",
    "    # (Sửa lỗi cảnh báo: '15T' -> '15min')\n",
    "    full_time_index = pd.date_range(start=df.index.min(), end=df.index.max(), freq='15min')\n",
    "    \n",
    "    # Tạo MultiIndex (cell_name, timestamp)\n",
    "    multi_index = pd.MultiIndex.from_product([all_cells, full_time_index], names=['cell_name', 'timestamp'])\n",
    "    \n",
    "    # Lấy các cột dữ liệu\n",
    "    df_data_only = df[FEATURE_COLS + ['cell_name']]\n",
    "    \n",
    "    # Đưa timestamp ra thành một cột\n",
    "    df_data_only = df_data_only.reset_index()\n",
    "    \n",
    "    # Xử lý các (cell_name, timestamp) bị trùng lặp\n",
    "    print(f\"Dữ liệu trước khi xử lý trùng lặp: {len(df_data_only)} hàng\")\n",
    "    df_grouped_unique = df_data_only.groupby(['cell_name', 'timestamp']).mean()\n",
    "    print(f\"Dữ liệu sau khi xử lý trùng lặp (groupby.mean): {len(df_grouped_unique)} hàng\")\n",
    "    \n",
    "    # Reindex với MultiIndex đầy đủ, điền 0 vào các chỗ thiếu\n",
    "    df_full = df_grouped_unique.reindex(multi_index, fill_value=0)\n",
    "    \n",
    "    # *** (BƯỚC SỬA LỖI KEYERROR) ***\n",
    "    \n",
    "    # 1. Reset TẤT CẢ các cấp index ('cell_name', 'timestamp') ra thành cột\n",
    "    df_full = df_full.reset_index() \n",
    "    \n",
    "    # 2. Đặt cột 'timestamp' làm index mới.\n",
    "    # 'cell_name' bây giờ sẽ tự động là một cột, chính xác như chúng ta muốn.\n",
    "    df_full = df_full.set_index('timestamp')\n",
    "    \n",
    "    # *** (KẾT THÚC SỬA LỖI) ***\n",
    "    \n",
    "    print(f\"Dữ liệu gốc có {len(df)} hàng.\")\n",
    "    print(f\"Dữ liệu đã điền đầy đủ (sau reindex) có {len(df_full)} hàng.\")\n",
    "    print(\"Hoàn tất xử lý.\")\n",
    "    print(\"\\n5 dòng đầu của dữ liệu đã xử lý đầy đủ:\")\n",
    "    print(df_full.head())\n",
    "\n",
    "else:\n",
    "    print(\"Lỗi: DataFrame 'df' không tồn tại. Vui lòng chạy lại Cell 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e765d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cấu hình mô hình: Input 2016 bước (3 Tuần), Output 672 bước (1 Tuần).\n",
      "Yêu cầu dữ liệu tối thiểu cho 1 mẫu: 2688 bước (28 ngày)\n",
      "\n",
      "Mốc Train (70%):  Kết thúc lúc 2025-11-01 16:37:30\n",
      "Mốc Val (20%):    Kết thúc lúc 2025-11-07 21:22:30 (Bắt đầu từ 2025-11-01 16:37:30)\n",
      "Mốc Test (10%):   Bắt đầu từ  2025-11-07 21:22:30\n",
      "\n",
      "Kích thước tập Train: (224964, 6)\n",
      "Kích thước tập Val:   (64260, 6)\n",
      "Kích thước tập Test:  (32184, 6)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- Cell 4 (GIẢI PHÁP): 2 Ngày -> 1 Ngày (70/20/10) ---\n",
    "\n",
    "# Data của chúng ta có tần suất 15 phút (4 mẫu/giờ)\n",
    "TIMESTEPS_PER_HOUR = 4\n",
    "TIMESTEPS_PER_DAY = 24 * TIMESTEPS_PER_HOUR # 96\n",
    "\n",
    "# *** (THAY ĐỔI QUAN TRỌNG TẠI ĐÂY) ***\n",
    "# Input: 2 ngày\n",
    "INPUT_DAYS = 2\n",
    "INPUT_STEPS = INPUT_DAYS * TIMESTEPS_PER_DAY # 2 * 96 = 192\n",
    "\n",
    "# Output: 1 ngày\n",
    "OUTPUT_DAYS = 1\n",
    "OUTPUT_STEPS = OUTPUT_DAYS * TIMESTEPS_PER_DAY # 1 * 96 = 96\n",
    "# *** (KẾT THÚC THAY ĐỔI) ***\n",
    "\n",
    "# Yêu cầu dữ liệu tối thiểu mới: 192 + 96 = 288 steps (3 ngày)\n",
    "print(f\"Cấu hình mô hình MỚI: Input {INPUT_STEPS} bước (2 ngày), Output {OUTPUT_STEPS} bước (1 ngày).\")\n",
    "print(f\"Yêu cầu dữ liệu tối thiểu cho 1 mẫu: 288 bước (3 ngày)\")\n",
    "\n",
    "# TÁCH DỮ LIỆU THEO THỜI GIAN (Tỷ lệ 70/20/10)\n",
    "if 'df_full' in locals():\n",
    "    total_duration = df_full.index.max() - df_full.index.min()\n",
    "    \n",
    "    # 70% cho Train\n",
    "    train_end_time = df_full.index.min() + total_duration * 0.7\n",
    "    \n",
    "    # Thêm 20% cho Validation (tổng 90%)\n",
    "    val_end_time = df_full.index.min() + total_duration * 0.9\n",
    "    \n",
    "    # 10% còn lại cho Test\n",
    "\n",
    "    print(f\"\\nMốc Train (70%):  Kết thúc lúc {train_end_time}\")\n",
    "    print(f\"Mốc Val (20%):    Kết thúc lúc {val_end_time} (Bắt đầu từ {train_end_time})\")\n",
    "    print(f\"Mốc Test (10%):   Bắt đầu từ  {val_end_time}\")\n",
    "\n",
    "    # Tách\n",
    "    train_df = df_full[df_full.index < train_end_time]\n",
    "    val_df = df_full[(df_full.index >= train_end_time) & (df_full.index < val_end_time)]\n",
    "    test_df = df_full[df_full.index >= val_end_time]\n",
    "    \n",
    "    print(f\"\\nKích thước tập Train: {train_df.shape}\")\n",
    "    print(f\"Kích thước tập Val:   {val_df.shape}\")\n",
    "    print(f\"Kích thước tập Test:  {test_df.shape}\")\n",
    "else:\n",
    "    print(\"Lỗi: DataFrame 'df_full' không tồn tại. Vui lòng chạy lại Cell 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd77b53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoàn tất scaling dữ liệu.\n",
      "Dữ liệu train sau khi scale (5 dòng đầu):\n",
      "                     ps_traffic_mb  avg_rrc_connected_user  prb_dl_used  \\\n",
      "timestamp                                                                 \n",
      "2025-10-11 00:00:00       0.015048                0.020689     0.047368   \n",
      "2025-10-11 00:15:00       0.000000                0.000000     0.000000   \n",
      "2025-10-11 00:30:00       0.000000                0.000000     0.000000   \n",
      "2025-10-11 00:45:00       0.000000                0.000000     0.000000   \n",
      "2025-10-11 01:00:00       0.021629                0.018869     0.047368   \n",
      "\n",
      "                     prb_dl_available_total  prb_utilization cell_name  \n",
      "timestamp                                                               \n",
      "2025-10-11 00:00:00                  0.9375         0.047368  EnodebA3  \n",
      "2025-10-11 00:15:00                  0.0000         0.000000  EnodebA3  \n",
      "2025-10-11 00:30:00                  0.0000         0.000000  EnodebA3  \n",
      "2025-10-11 00:45:00                  0.0000         0.000000  EnodebA3  \n",
      "2025-10-11 01:00:00                  0.9375         0.047368  EnodebA3  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Cell 5: Chuẩn hóa (Scaling) Dữ liệu ---\n",
    "# Chúng ta phải fit Scaler CHỈ trên dữ liệu train để tránh rò rỉ dữ liệu\n",
    "\n",
    "if 'train_df' in locals():\n",
    "    # Khởi tạo Scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # 1. Fit scaler CHỈ trên dữ liệu train (chỉ các cột features)\n",
    "    # Chúng ta phải fit trên toàn bộ dữ liệu train để scaler học được min/max\n",
    "    scaler.fit(train_df[FEATURE_COLS])\n",
    "    \n",
    "    # 2. Transform cả 3 tập\n",
    "    # Lưu lại 'cell_name' để dùng cho việc nhóm\n",
    "    train_cells = train_df['cell_name']\n",
    "    val_cells = val_df['cell_name']\n",
    "    test_cells = test_df['cell_name']\n",
    "\n",
    "    # Transform\n",
    "    train_scaled_data = scaler.transform(train_df[FEATURE_COLS])\n",
    "    val_scaled_data = scaler.transform(val_df[FEATURE_COLS])\n",
    "    test_scaled_data = scaler.transform(test_df[FEATURE_COLS])\n",
    "    \n",
    "    # 3. Tạo lại DataFrame đã scale (việc này giúp nhóm dễ dàng hơn)\n",
    "    scaled_train_df = pd.DataFrame(train_scaled_data, columns=FEATURE_COLS, index=train_df.index)\n",
    "    scaled_train_df['cell_name'] = train_cells\n",
    "\n",
    "    scaled_val_df = pd.DataFrame(val_scaled_data, columns=FEATURE_COLS, index=val_df.index)\n",
    "    scaled_val_df['cell_name'] = val_cells\n",
    "\n",
    "    scaled_test_df = pd.DataFrame(test_scaled_data, columns=FEATURE_COLS, index=test_df.index)\n",
    "    scaled_test_df['cell_name'] = test_cells\n",
    "    \n",
    "    print(\"Hoàn tất scaling dữ liệu.\")\n",
    "    print(\"Dữ liệu train sau khi scale (5 dòng đầu):\")\n",
    "    print(scaled_train_df.head())\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b38121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Cell 6: Hàm tạo cửa sổ (Windowing) ---\n",
    "# Đây là hàm quan trọng nhất:\n",
    "# Nó sẽ duyệt qua TỪNG cell_name, sau đó tạo các cặp (X, y)\n",
    "# X = 672 bước (7 ngày), y = 96 bước (1 ngày)\n",
    "\n",
    "def create_windows(data_df, input_steps, output_steps, feature_cols):\n",
    "    \"\"\"\n",
    "    Tạo các cửa sổ X (input) và y (output) từ dữ liệu đã scale,\n",
    "    nhóm theo 'cell_name'.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Nhóm dữ liệu theo từng cell\n",
    "    grouped = data_df.groupby('cell_name')\n",
    "    \n",
    "    total_cells = len(grouped)\n",
    "    print(f\"Bắt đầu tạo cửa sổ cho {total_cells} cell...\")\n",
    "    \n",
    "    cell_count = 0\n",
    "    for cell_id, cell_data in grouped:\n",
    "        cell_count += 1\n",
    "        if cell_count % 50 == 0:\n",
    "            print(f\"  ...đang xử lý cell {cell_count}/{total_cells} (ID: {cell_id})\")\n",
    "            \n",
    "        # Lấy dữ liệu số của cell này\n",
    "        cell_features = cell_data[feature_cols].values\n",
    "        \n",
    "        # Tổng số mẫu của cell này\n",
    "        total_samples = len(cell_features)\n",
    "        \n",
    "        # Tổng độ dài cần thiết cho 1 cửa sổ\n",
    "        total_window_len = input_steps + output_steps\n",
    "        \n",
    "        # Trượt cửa sổ\n",
    "        for i in range(total_samples - total_window_len + 1):\n",
    "            # i là điểm bắt đầu của input\n",
    "            input_start = i\n",
    "            input_end = i + input_steps\n",
    "            \n",
    "            # output_end là điểm kết thúc của output\n",
    "            output_end = input_end + output_steps\n",
    "            \n",
    "            # Lấy cửa sổ X và y\n",
    "            window_X = cell_features[input_start:input_end, :]\n",
    "            window_y = cell_features[input_end:output_end, :]\n",
    "            \n",
    "            X.append(window_X)\n",
    "            y.append(window_y)\n",
    "            \n",
    "    print(f\"Hoàn tất tạo cửa sổ. Đã tạo {len(X)} mẫu.\")\n",
    "    \n",
    "    # Chuyển list thành Numpy array\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cb7a3660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Đang tạo mẫu Train (X_train, y_train) ---\n",
      "Bắt đầu tạo cửa sổ cho 108 cell...\n",
      "  ...đang xử lý cell 50/108 (ID: EnodebE2)\n",
      "  ...đang xử lý cell 100/108 (ID: EnodebK1)\n",
      "Hoàn tất tạo cửa sổ. Đã tạo 0 mẫu.\n",
      "\n",
      "--- Đang tạo mẫu Validation (X_val, y_val) ---\n",
      "Bắt đầu tạo cửa sổ cho 108 cell...\n",
      "  ...đang xử lý cell 50/108 (ID: EnodebE2)\n",
      "  ...đang xử lý cell 100/108 (ID: EnodebK1)\n",
      "Hoàn tất tạo cửa sổ. Đã tạo 0 mẫu.\n",
      "\n",
      "--- Đang tạo mẫu Test (X_test, y_test) ---\n",
      "Bắt đầu tạo cửa sổ cho 108 cell...\n",
      "  ...đang xử lý cell 50/108 (ID: EnodebE2)\n",
      "  ...đang xử lý cell 100/108 (ID: EnodebK1)\n",
      "Hoàn tất tạo cửa sổ. Đã tạo 0 mẫu.\n",
      "\n",
      "--- Kích thước dữ liệu (Shape) ---\n",
      "X_train shape: (0,)\n",
      "y_train shape: (0,)\n",
      "X_val shape:   (0,)\n",
      "y_val shape:   (0,)\n",
      "X_test shape:  (0,)\n",
      "y_test shape:  (0,)\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 7: Áp dụng hàm Windowing ---\n",
    "\n",
    "if 'scaled_train_df' in locals():\n",
    "    print(\"--- Đang tạo mẫu Train (X_train, y_train) ---\")\n",
    "    X_train, y_train = create_windows(scaled_train_df, INPUT_STEPS, OUTPUT_STEPS, FEATURE_COLS)\n",
    "    \n",
    "    print(\"\\n--- Đang tạo mẫu Validation (X_val, y_val) ---\")\n",
    "    X_val, y_val = create_windows(scaled_val_df, INPUT_STEPS, OUTPUT_STEPS, FEATURE_COLS)\n",
    "    \n",
    "    print(\"\\n--- Đang tạo mẫu Test (X_test, y_test) ---\")\n",
    "    X_test, y_test = create_windows(scaled_test_df, INPUT_STEPS, OUTPUT_STEPS, FEATURE_COLS)\n",
    "    \n",
    "    print(\"\\n--- Kích thước dữ liệu (Shape) ---\")\n",
    "    print(f\"X_train shape: {X_train.shape}\") # (Số mẫu, 672, N_FEATURES)\n",
    "    print(f\"y_train shape: {y_train.shape}\") # (Số mẫu, 96, N_FEATURES)\n",
    "    print(f\"X_val shape:   {X_val.shape}\")\n",
    "    print(f\"y_val shape:   {y_val.shape}\")\n",
    "    print(f\"X_test shape:  {X_test.shape}\")\n",
    "    print(f\"y_test shape:  {y_test.shape}\")\n",
    "else:\n",
    "    print(\"Lỗi: Dữ liệu đã scale không tồn tại. Vui lòng chạy lại Cell 5.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639623ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lỗi: Không có dữ liệu training (X_train) để xây dựng mô hình.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- Cell 8 (Cập nhật): Xây dựng mô hình LSTM (Seq2Seq) ---\n",
    "# Cập nhật Input Shape cho 2 ngày (192 steps)\n",
    "\n",
    "if 'X_train' in locals() and X_train.shape[0] > 0:\n",
    "    # Xóa mô hình cũ (nếu có)\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Định nghĩa các hằng số của mô hình\n",
    "    N_UNITS_LSTM = 100 # Số units trong lớp LSTM\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    # ---- ENCODER (Bộ mã hóa) ----\n",
    "    # *** (THAY ĐỔI QUAN TRỌNG TẠI ĐÂY) ***\n",
    "    # Input shape bây giờ phải khớp với INPUT_STEPS mới (192)\n",
    "    model.add(Input(shape=(INPUT_STEPS, N_FEATURES)))\n",
    "    # *** (KẾT THÚC THAY ĐỔI) ***\n",
    "    \n",
    "    model.add(LSTM(N_UNITS_LSTM, activation='relu'))\n",
    "    \n",
    "    # ---- REPEATER ----\n",
    "    # Lặp lại 96 lần (OUTPUT_STEPS)\n",
    "    model.add(RepeatVector(OUTPUT_STEPS))\n",
    "    \n",
    "    # ---- DECODER (Bộ giải mã) ----\n",
    "    # return_sequences=True là bắt buộc\n",
    "    model.add(LSTM(N_UNITS_LSTM, activation='relu', return_sequences=True))\n",
    "    \n",
    "    # Lớp Output: Áp dụng 1 lớp Dense cho TỪNG bước thời gian (trong 96 bước)\n",
    "    model.add(TimeDistributed(Dense(N_FEATURES)))\n",
    "    \n",
    "    # ---- Compile mô hình ----\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    model.summary()\n",
    "else:\n",
    "    print(\"Lỗi: Không có dữ liệu training (X_train) để xây dựng mô hình.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "007b42f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu huấn luyện (training) mô hình...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n  • training=True\n  • mask=None\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;66;03m# Số lượt học (tăng lên 50-100 nếu có GPU)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m \u001b[38;5;66;03m# Số mẫu học trong 1 lần\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Dừng sớm nếu val_loss không cải thiện\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHoàn tất huấn luyện!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Lưu mô hình (tùy chọn)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# model.save('kpi_lstm_model.h5')\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# print(\"Đã lưu mô hình vào 'kpi_lstm_model.h5'\")\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\firek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\firek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n  • training=True\n  • mask=None\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# --- Cell 9: Huấn luyện mô hình ---\n",
    "\n",
    "if 'model' in locals():\n",
    "    print(\"Bắt đầu huấn luyện (training) mô hình...\")\n",
    "    \n",
    "    # Hằng số huấn luyện\n",
    "    EPOCHS = 20 # Số lượt học (tăng lên 50-100 nếu có GPU)\n",
    "    BATCH_SIZE = 64 # Số mẫu học trong 1 lần\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[\n",
    "            # Dừng sớm nếu val_loss không cải thiện\n",
    "            keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"Hoàn tất huấn luyện!\")\n",
    "    \n",
    "    # Lưu mô hình (tùy chọn)\n",
    "    # model.save('kpi_lstm_model.h5')\n",
    "    # print(\"Đã lưu mô hình vào 'kpi_lstm_model.h5'\")\n",
    "\n",
    "else:\n",
    "    print(\"Lỗi: Mô hình chưa được định nghĩa.\")\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e0a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Cell 10: Đánh giá Loss và \"Accuracy\" ---\n",
    "\n",
    "if 'history' in locals():\n",
    "    print(\"--- Đánh giá kết quả huấn luyện ---\")\n",
    "\n",
    "    # 1. Trực quan hóa Loss (MSE) và MAE\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    \n",
    "    # Plot Loss (MSE)\n",
    "    ax1.plot(history.history['loss'], label='Train Loss (MSE)')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss (MSE)')\n",
    "    ax1.set_title('Model Loss (Mean Squared Error)')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss (MSE)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot \"Accuracy\" (Chúng ta dùng MAE - Mean Absolute Error)\n",
    "    # GHI CHÚ: \"Accuracy\" là metric cho bài toán Phân loại (Classification).\n",
    "    # Đối với bài toán Hồi quy (Regression) như dự đoán KPI, \n",
    "    # chúng ta dùng MAE để đo \"độ chính xác\" (sai số tuyệt đối trung bình).\n",
    "    \n",
    "    ax2.plot(history.history['mae'], label='Train MAE')\n",
    "    ax2.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    ax2.set_title('Model \"Accuracy\" (Mean Absolute Error)')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Mean Absolute Error (MAE)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # 2. Đánh giá trên tập TEST (Dữ liệu chưa từng thấy)\n",
    "    print(\"\\n--- Đánh giá trên tập Test ---\")\n",
    "    # model.evaluate sẽ trả về [loss, metric_1, metric_2, ...]\n",
    "    # Tương ứng với compile(loss='mse', metrics=['mae'])\n",
    "    test_results = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    test_loss_mse = test_results[0]\n",
    "    test_metric_mae = test_results[1]\n",
    "\n",
    "    print(f\"  Test Loss (MSE): {test_loss_mse:.6f}\")\n",
    "    print(f\"  Test MAE (Mean Absolute Error): {test_metric_mae:.6f}\")\n",
    "    \n",
    "    print(\"\\nGiải thích MAE:\")\n",
    "    print(f\"Giá trị MAE = {test_metric_mae:.6f} (trên dữ liệu đã scale từ 0-1).\")\n",
    "    print(\"Điều này có nghĩa là, trên thang 0-1, dự đoán của mô hình\")\n",
    "    print(f\"sai lệch trung bình khoảng {test_metric_mae:.6f} so với giá trị thực tế.\")\n",
    "    print(\"(Để có MAE theo đơn vị gốc (MB, Users...), chúng ta cần dùng scaler.inverse_transform)\")\n",
    "    \n",
    "else:\n",
    "    print(\"Lỗi: Biến 'history' không tồn tại. Mô hình chưa được huấn luyện.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
