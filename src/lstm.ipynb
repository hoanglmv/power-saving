{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 1: Tải các thư viện ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "# Cấu hình hiển thị\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ac6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 2 (train.ipynb - SỬA LỖI CHO CSV): Tải dữ liệu đã xử lý ---\n",
    "file_name = 'kpi_processed.csv' # <-- Đã đổi tên file\n",
    "try:\n",
    "    # *** THAY ĐỔI QUAN TRỌNG ***\n",
    "    # Chúng ta dùng pd.read_csv và thêm 2 tham số:\n",
    "    # 1. index_col=0: Báo cho Pandas rằng cột đầu tiên (cột 0) là index.\n",
    "    # 2. parse_dates=True: Báo cho Pandas chuyển đổi index đó thành Datetime.\n",
    "    df = pd.read_csv(file_name, index_col=0, parse_dates=True)\n",
    "    \n",
    "    print(f\"Tải file '{file_name}' thành công.\")\n",
    "    print(f\"Dữ liệu có {len(df)} hàng, kéo dài từ {df.index.min()} đến {df.index.max()}.\")\n",
    "    print(\"\\nThông tin dữ liệu (df.info()):\")\n",
    "    df.info() \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"LỖI: Không thể tải file '{file_name}'.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eeffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Cell 3: Xử lý dữ liệu (Quan trọng!) ---\n",
    "# Mục tiêu: Đảm bảo MỌI cell_name đều có đầy đủ 15 phút, không bị ngắt quãng.\n",
    "# Nếu thiếu, chúng ta sẽ lấp đầy bằng 0.\n",
    "if 'df' in locals():\n",
    "    # Xác định các cột KPI để dự đoán\n",
    "    FEATURE_COLS = ['ps_traffic_mb', 'avg_rrc_connected_user', 'prb_dl_used', 'prb_dl_available_total', 'prb_utilization']\n",
    "    N_FEATURES = len(FEATURE_COLS)\n",
    "    print(f\"Dự đoán {N_FEATURES} features: {FEATURE_COLS}\")\n",
    "    # Tạo ra một DataFrame đầy đủ cho MỌI cell\n",
    "    print(\"Đang xử lý: Đảm bảo dữ liệu 15 phút đầy đủ cho mỗi cell...\")\n",
    "    # Lấy tất cả các cell độc nhất\n",
    "    all_cells = df['cell_name'].unique()\n",
    "    # Tạo ra một index thời gian 15 phút đầy đủ từ đầu đến cuối\n",
    "    # (Sửa lỗi cảnh báo: '15T' -> '15min')\n",
    "    full_time_index = pd.date_range(start=df.index.min(), end=df.index.max(), freq='15min')\n",
    "    # Tạo MultiIndex (cell_name, timestamp)\n",
    "    multi_index = pd.MultiIndex.from_product([all_cells, full_time_index], names=['cell_name', 'timestamp'])\n",
    "    # Lấy các cột dữ liệu\n",
    "    df_data_only = df[FEATURE_COLS + ['cell_name']]\n",
    "    # Đưa timestamp ra thành một cột\n",
    "    df_data_only = df_data_only.reset_index()\n",
    "    # Xử lý các (cell_name, timestamp) bị trùng lặp\n",
    "    print(f\"Dữ liệu trước khi xử lý trùng lặp: {len(df_data_only)} hàng\")\n",
    "    df_grouped_unique = df_data_only.groupby(['cell_name', 'timestamp']).mean()\n",
    "    print(f\"Dữ liệu sau khi xử lý trùng lặp (groupby.mean): {len(df_grouped_unique)} hàng\")\n",
    "    # Reindex với MultiIndex đầy đủ, điền 0 vào các chỗ thiếu\n",
    "    df_full = df_grouped_unique.reindex(multi_index, fill_value=0)\n",
    "    # *** (BƯỚC SỬA LỖI KEYERROR) ***\n",
    "    # 1. Reset TẤT CẢ các cấp index ('cell_name', 'timestamp') ra thành cột\n",
    "    df_full = df_full.reset_index() \n",
    "    # 2. Đặt cột 'timestamp' làm index mới.\n",
    "    # 'cell_name' bây giờ sẽ tự động là một cột, chính xác như chúng ta muốn.\n",
    "    df_full = df_full.set_index('timestamp')\n",
    "    # *** (KẾT THÚC SỬA LỖI) ***\n",
    "    print(f\"Dữ liệu gốc có {len(df)} hàng.\")\n",
    "    print(f\"Dữ liệu đã điền đầy đủ (sau reindex) có {len(df_full)} hàng.\")\n",
    "    print(\"Hoàn tất xử lý.\")\n",
    "    print(\"\\n5 dòng đầu của dữ liệu đã xử lý đầy đủ:\")\n",
    "    print(df_full.head())\n",
    "else:\n",
    "    print(\"Lỗi: DataFrame 'df' không tồn tại. Vui lòng chạy lại Cell 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 4: \n",
    "# Data có tần suất 15 phút (4 mẫu/giờ)\n",
    "TIMESTEPS_PER_HOUR = 4\n",
    "TIMESTEPS_PER_DAY = 24 * TIMESTEPS_PER_HOUR # 96\n",
    "# Input: 2 ngày\n",
    "INPUT_DAYS = 2\n",
    "INPUT_STEPS = INPUT_DAYS * TIMESTEPS_PER_DAY # 2 * 96 = 192\n",
    "# Output: 1 ngày\n",
    "OUTPUT_DAYS = 1\n",
    "OUTPUT_STEPS = OUTPUT_DAYS * TIMESTEPS_PER_DAY # 1 * 96 = 96\n",
    "\n",
    "print(f\"Cấu hình mô hình: Input {INPUT_STEPS} bước (2 ngày), Output {OUTPUT_STEPS} bước (1 ngày).\")\n",
    "print(f\"Yêu cầu dữ liệu tối thiểu cho 1 mẫu: 276 bước (28 ngày)\")\n",
    "\n",
    "# TÁCH DỮ LIỆU THEO THỜI GIAN (70/20/10)\n",
    "if 'df_full' in locals():\n",
    "    total_duration = df_full.index.max() - df_full.index.min()\n",
    "    # 70% cho Train\n",
    "    train_end_time = df_full.index.min() + total_duration * 0.7\n",
    "    # Thêm 20% cho Validation (tổng 90%)\n",
    "    val_end_time = df_full.index.min() + total_duration * 0.9\n",
    "    # 10% còn lại cho Test\n",
    "    train_df = df_full[df_full.index < train_end_time]\n",
    "    val_df = df_full[(df_full.index >= train_end_time) & (df_full.index < val_end_time)]\n",
    "    test_df = df_full[df_full.index >= val_end_time]\n",
    "    print(f\"\\n Train: {train_df.shape}\")\n",
    "    print(f\"Val:   {val_df.shape}\")\n",
    "    print(f\"Test:  {test_df.shape}\")\n",
    "else:\n",
    "    print(\"Lỗi: DataFrame 'df_full' không tồn tại. Vui lòng chạy lại Cell 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd77b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Cell 5: Chuẩn hóa (Scaling) Dữ liệu ---\n",
    "# Chúng ta phải fit Scaler CHỈ trên dữ liệu train để tránh rò rỉ dữ liệu\n",
    "\n",
    "# Kiểm tra xem có NaN hay Inf trong train_df không\n",
    "print(\"Kiểm tra dữ liệu bẩn:\")\n",
    "print(\"Số lượng NaN:\", train_df.isna().sum().sum())\n",
    "print(\"Số lượng Inf:\", np.isinf(train_df[FEATURE_COLS].values).sum())\n",
    "\n",
    "# Xử lý thay thế (nếu có)\n",
    "train_df = train_df.replace([np.inf, -np.inf], 0)\n",
    "train_df = train_df.fillna(0)\n",
    "\n",
    "val_df = val_df.replace([np.inf, -np.inf], 0)\n",
    "val_df = val_df.fillna(0)\n",
    "\n",
    "test_df = test_df.replace([np.inf, -np.inf], 0)\n",
    "test_df = test_df.fillna(0)\n",
    "\n",
    "print(\"Đã làm sạch dữ liệu NaN/Inf.\")\n",
    "if 'train_df' in locals():\n",
    "    # Khởi tạo Scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # 1. Fit scaler CHỈ trên dữ liệu train (chỉ các cột features)\n",
    "    # Chúng ta phải fit trên toàn bộ dữ liệu train để scaler học được min/max\n",
    "    scaler.fit(train_df[FEATURE_COLS])\n",
    "    \n",
    "    # 2. Transform cả 3 tập\n",
    "    # Lưu lại 'cell_name' để dùng cho việc nhóm\n",
    "    train_cells = train_df['cell_name']\n",
    "    val_cells = val_df['cell_name']\n",
    "    test_cells = test_df['cell_name']\n",
    "\n",
    "    # Transform\n",
    "    train_scaled_data = scaler.transform(train_df[FEATURE_COLS])\n",
    "    val_scaled_data = scaler.transform(val_df[FEATURE_COLS])\n",
    "    test_scaled_data = scaler.transform(test_df[FEATURE_COLS])\n",
    "    \n",
    "    # 3. Tạo lại DataFrame đã scale (việc này giúp nhóm dễ dàng hơn)\n",
    "    scaled_train_df = pd.DataFrame(train_scaled_data, columns=FEATURE_COLS, index=train_df.index)\n",
    "    scaled_train_df['cell_name'] = train_cells\n",
    "\n",
    "    scaled_val_df = pd.DataFrame(val_scaled_data, columns=FEATURE_COLS, index=val_df.index)\n",
    "    scaled_val_df['cell_name'] = val_cells\n",
    "\n",
    "    scaled_test_df = pd.DataFrame(test_scaled_data, columns=FEATURE_COLS, index=test_df.index)\n",
    "    scaled_test_df['cell_name'] = test_cells\n",
    "    \n",
    "    print(\"Hoàn tất scaling dữ liệu.\")\n",
    "    print(\"Dữ liệu train sau khi scale (5 dòng đầu):\")\n",
    "    print(scaled_train_df.head())\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b38121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Cell 6: Hàm tạo cửa sổ (Windowing) ---\n",
    "# Đây là hàm quan trọng nhất:\n",
    "# Nó sẽ duyệt qua TỪNG cell_name, sau đó tạo các cặp (X, y)\n",
    "# X = 672 bước (7 ngày), y = 96 bước (1 ngày)\n",
    "\n",
    "def create_windows(data_df, input_steps, output_steps, feature_cols):\n",
    "    \"\"\"\n",
    "    Tạo các cửa sổ X (input) và y (output) từ dữ liệu đã scale,\n",
    "    nhóm theo 'cell_name'.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Nhóm dữ liệu theo từng cell\n",
    "    grouped = data_df.groupby('cell_name')\n",
    "    \n",
    "    total_cells = len(grouped)\n",
    "    print(f\"Bắt đầu tạo cửa sổ cho {total_cells} cell...\")\n",
    "    \n",
    "    cell_count = 0\n",
    "    for cell_id, cell_data in grouped:\n",
    "        cell_count += 1\n",
    "        if cell_count % 50 == 0:\n",
    "            print(f\"  ...đang xử lý cell {cell_count}/{total_cells} (ID: {cell_id})\")\n",
    "            \n",
    "        # Lấy dữ liệu số của cell này\n",
    "        cell_features = cell_data[feature_cols].values\n",
    "        \n",
    "        # Tổng số mẫu của cell này\n",
    "        total_samples = len(cell_features)\n",
    "        \n",
    "        # Tổng độ dài cần thiết cho 1 cửa sổ\n",
    "        total_window_len = input_steps + output_steps\n",
    "        \n",
    "        # Trượt cửa sổ\n",
    "        for i in range(total_samples - total_window_len + 1):\n",
    "            # i là điểm bắt đầu của input\n",
    "            input_start = i\n",
    "            input_end = i + input_steps\n",
    "            \n",
    "            # output_end là điểm kết thúc của output\n",
    "            output_end = input_end + output_steps\n",
    "            \n",
    "            # Lấy cửa sổ X và y\n",
    "            window_X = cell_features[input_start:input_end, :]\n",
    "            window_y = cell_features[input_end:output_end, :]\n",
    "            \n",
    "            X.append(window_X)\n",
    "            y.append(window_y)\n",
    "            \n",
    "    print(f\"Hoàn tất tạo cửa sổ. Đã tạo {len(X)} mẫu.\")\n",
    "    \n",
    "    # Chuyển list thành Numpy array\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 7: Áp dụng hàm Windowing ---\n",
    "\n",
    "if 'scaled_train_df' in locals():\n",
    "    print(\"--- Đang tạo mẫu Train (X_train, y_train) ---\")\n",
    "    X_train, y_train = create_windows(scaled_train_df, INPUT_STEPS, OUTPUT_STEPS, FEATURE_COLS)\n",
    "    \n",
    "    print(\"\\n--- Đang tạo mẫu Validation (X_val, y_val) ---\")\n",
    "    X_val, y_val = create_windows(scaled_val_df, INPUT_STEPS, OUTPUT_STEPS, FEATURE_COLS)\n",
    "    \n",
    "    print(\"\\n--- Đang tạo mẫu Test (X_test, y_test) ---\")\n",
    "    X_test, y_test = create_windows(scaled_test_df, INPUT_STEPS, OUTPUT_STEPS, FEATURE_COLS)\n",
    "    \n",
    "    print(\"\\n--- Kích thước dữ liệu (Shape) ---\")\n",
    "    print(f\"X_train shape: {X_train.shape}\") # (Số mẫu, 672, N_FEATURES)\n",
    "    print(f\"y_train shape: {y_train.shape}\") # (Số mẫu, 96, N_FEATURES)\n",
    "    print(f\"X_val shape:   {X_val.shape}\")\n",
    "    print(f\"y_val shape:   {y_val.shape}\")\n",
    "    print(f\"X_test shape:  {X_test.shape}\")\n",
    "    print(f\"y_test shape:  {y_test.shape}\")\n",
    "else:\n",
    "    print(\"Lỗi: Dữ liệu đã scale không tồn tại. Vui lòng chạy lại Cell 5.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639623ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 8 (Cập nhật): Xây dựng mô hình LSTM (Seq2Seq) ---\n",
    "# Cập nhật Input (2016 steps) và Output (672 steps)\n",
    "# --- SỬA LẠI CELL 8 ---\n",
    "if 'X_train' in locals() and X_train.shape[0] > 0:\n",
    "    keras.backend.clear_session()\n",
    "    N_UNITS_LSTM = 100 \n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input\n",
    "    model.add(Input(shape=(INPUT_STEPS, N_FEATURES)))\n",
    "    \n",
    "    # Encoder: ĐỔI 'relu' THÀNH 'tanh'\n",
    "    model.add(LSTM(N_UNITS_LSTM, activation='tanh')) \n",
    "    \n",
    "    # Repeater\n",
    "    model.add(RepeatVector(OUTPUT_STEPS))\n",
    "    \n",
    "    # Decoder: ĐỔI 'relu' THÀNH 'tanh'\n",
    "    model.add(LSTM(N_UNITS_LSTM, activation='tanh', return_sequences=True))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(TimeDistributed(Dense(N_FEATURES)))\n",
    "    \n",
    "    # --- QUAN TRỌNG: Cấu hình Optimizer để kẹp Gradient (Clipnorm) ---\n",
    "    # Nếu gradient vẫn quá lớn, clipnorm sẽ cắt bớt nó lại\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    \n",
    "else:\n",
    "    print(\"Lỗi: Không có dữ liệu training (X_train) để xây dựng mô hình.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007b42f3",
   "metadata": {},
   "outputs": [],
       "source": [
       "\n",
       "# %%\n",
       "# --- Cell 9: Huấn luyện mô hình ---\n",
       "\n",
       "if 'model' in locals():\n",
       "    print(\"Bắt đầu huấn luyện (training) mô hình...\")\n",
       "    \n",
       "    # Hằng số huấn luyện\n",
       "    EPOCHS = 20 # Số lượt học (tăng lên 50-100 nếu có GPU)\n",
       "    BATCH_SIZE = 64 # Số mẫu học trong 1 lần\n",
       "    \n",
       "    history = model.fit(\n",
       "        X_train, y_train,\n",
       "        epochs=EPOCHS,\n",
       "        batch_size=BATCH_SIZE,\n",
       "        validation_data=(X_val, y_val),\n",
       "        callbacks=[\n",
       "            # Dừng sớm nếu val_loss không cải thiện\n",
       "            keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
       "        ]\n",
       "    )\n",
       "    \n",
       "    print(\"Hoàn tất huấn luyện!\")\n",
       "    \n",
       "    # Lưu mô hình (tùy chọn)\n",
       "    model.save('lstm_model.h5')\n",
       "    print(\"Đã lưu mô hình vào 'lstm_model.h5'\")\n",
       "\n",
       "else:\n",
       "    print(\"Lỗi: Mô hình chưa được định nghĩa.\")\n",
       "\n",
       "# %%"
      ]  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e0a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Cell 10: Đánh giá Loss và \"Accuracy\" ---\n",
    "\n",
    "if 'history' in locals():\n",
    "    print(\"--- Đánh giá kết quả huấn luyện ---\")\n",
    "\n",
    "    # 1. Trực quan hóa Loss (MSE) và MAE\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    \n",
    "    # Plot Loss (MSE)\n",
    "    ax1.plot(history.history['loss'], label='Train Loss (MSE)')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss (MSE)')\n",
    "    ax1.set_title('Model Loss (Mean Squared Error)')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss (MSE)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot \"Accuracy\" (Chúng ta dùng MAE - Mean Absolute Error)\n",
    "    # GHI CHÚ: \"Accuracy\" là metric cho bài toán Phân loại (Classification).\n",
    "    # Đối với bài toán Hồi quy (Regression) như dự đoán KPI, \n",
    "    # chúng ta dùng MAE để đo \"độ chính xác\" (sai số tuyệt đối trung bình).\n",
    "    \n",
    "    ax2.plot(history.history['mae'], label='Train MAE')\n",
    "    ax2.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    ax2.set_title('Model \"Accuracy\" (Mean Absolute Error)')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Mean Absolute Error (MAE)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # 2. Đánh giá trên tập TEST (Dữ liệu chưa từng thấy)\n",
    "    print(\"\\n--- Đánh giá trên tập Test ---\")\n",
    "    # model.evaluate sẽ trả về [loss, metric_1, metric_2, ...]\n",
    "    # Tương ứng với compile(loss='mse', metrics=['mae'])\n",
    "    test_results = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    test_loss_mse = test_results[0]\n",
    "    test_metric_mae = test_results[1]\n",
    "\n",
    "    print(f\"  Test Loss (MSE): {test_loss_mse:.6f}\")\n",
    "    print(f\"  Test MAE (Mean Absolute Error): {test_metric_mae:.6f}\")\n",
    "    \n",
    "    print(\"\\nGiải thích MAE:\")\n",
    "    print(f\"Giá trị MAE = {test_metric_mae:.6f} (trên dữ liệu đã scale từ 0-1).\")\n",
    "    print(\"Điều này có nghĩa là, trên thang 0-1, dự đoán của mô hình\")\n",
    "    print(f\"sai lệch trung bình khoảng {test_metric_mae:.6f} so với giá trị thực tế.\")\n",
    "    print(\"(Để có MAE theo đơn vị gốc (MB, Users...), chúng ta cần dùng scaler.inverse_transform)\")\n",
    "    \n",
    "else:\n",
    "    print(\"Lỗi: Biến 'history' không tồn tại. Mô hình chưa được huấn luyện.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f42b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 11: So sánh kết quả dự đoán với giá trị thực tế ---\n",
    "\n",
    "if 'model' in locals() and 'X_test' in locals() and 'y_test' in locals() and 'scaler' in locals():\n",
    "    print(\"--- Trực quan hóa kết quả dự đoán trên tập Test ---\")\n",
    "\n",
    "    # 1. Dự đoán trên tập Test\n",
    "    # Chọn một batch từ X_test để dự đoán\n",
    "    # (Để đơn giản, ta lấy một vài mẫu đầu tiên hoặc một mẫu ngẫu nhiên)\n",
    "    num_samples_to_plot = min(5, X_test.shape[0]) # Vẽ 5 mẫu hoặc ít hơn nếu X_test ít hơn\n",
    "\n",
    "    if num_samples_to_plot == 0:\n",
    "        print(\"Không có mẫu nào trong X_test để dự đoán và trực quan hóa.\")\n",
    "    else:\n",
    "        # Lấy các mẫu đầu tiên từ X_test và y_test\n",
    "        X_test_subset = X_test[:num_samples_to_plot]\n",
    "        y_test_subset = y_test[:num_samples_to_plot]\n",
    "\n",
    "        # Thực hiện dự đoán\n",
    "        y_pred_scaled = model.predict(X_test_subset)\n",
    "\n",
    "        # Đảo ngược quá trình chuẩn hóa (Inverse Scaling) cho cả giá trị thực và dự đoán\n",
    "        # Chúng ta cần reshape lại dữ liệu thành 2D trước khi inverse_transform\n",
    "        \n",
    "        # Reshape y_test_subset (batch_size, output_steps, n_features) -> (batch_size * output_steps, n_features)\n",
    "        y_true_reshaped = y_test_subset.reshape(-1, N_FEATURES)\n",
    "        y_true_original = scaler.inverse_transform(y_true_reshaped)\n",
    "        y_true_original = y_true_original.reshape(num_samples_to_plot, OUTPUT_STEPS, N_FEATURES)\n",
    "\n",
    "        # Reshape y_pred_scaled (batch_size, output_steps, n_features) -> (batch_size * output_steps, n_features)\n",
    "        y_pred_reshaped = y_pred_scaled.reshape(-1, N_FEATURES)\n",
    "        y_pred_original = scaler.inverse_transform(y_pred_reshaped)\n",
    "        y_pred_original = y_pred_original.reshape(num_samples_to_plot, OUTPUT_STEPS, N_FEATURES)\n",
    "\n",
    "        # 2. Vẽ biểu đồ so sánh cho từng mẫu\n",
    "        for i in range(num_samples_to_plot):\n",
    "            print(f\"\\n--- So sánh Mẫu #{i+1} ---\")\n",
    "            \n",
    "            fig, axes = plt.subplots(N_FEATURES, 1, figsize=(15, 5 * N_FEATURES), sharex=True)\n",
    "            if N_FEATURES == 1: # Xử lý trường hợp chỉ có 1 feature (axes sẽ không phải mảng)\n",
    "                axes = [axes]\n",
    "\n",
    "            for j, feature_name in enumerate(FEATURE_COLS):\n",
    "                ax = axes[j]\n",
    "                ax.plot(y_true_original[i, :, j], label=f'Thực tế ({feature_name})', color='blue', marker='o', linestyle='-')\n",
    "                ax.plot(y_pred_original[i, :, j], label=f'Dự đoán ({feature_name})', color='red', marker='x', linestyle='--')\n",
    "                ax.set_title(f'Dự đoán {feature_name} (Mẫu #{i+1})')\n",
    "                ax.set_xlabel('Bước thời gian (15 phút)')\n",
    "                ax.set_ylabel(f'Giá trị {feature_name}')\n",
    "                ax.legend()\n",
    "                ax.grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        print(\"\\nHoàn tất trực quan hóa.\")\n",
    "\n",
    "else:\n",
    "    print(\"Lỗi: Không thể trực quan hóa. Đảm bảo 'model', 'X_test', 'y_test', 'scaler' đã tồn tại và X_test không rỗng.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
