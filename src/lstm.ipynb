{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef4b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: Tải các thư viện ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "# Cấu hình hiển thị\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "744ac6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tải file 'kpi_processed.csv' thành công.\n",
      "Dữ liệu có 313186 hàng, kéo dài từ 2025-10-11 00:00:00 đến 2025-11-10 23:45:00.\n",
      "\n",
      "Thông tin dữ liệu (df.info()):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 313186 entries, 2025-10-11 00:00:00 to 2025-11-10 23:00:00\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   enodeb                  313186 non-null  object \n",
      " 1   cell_name               313186 non-null  object \n",
      " 2   ps_traffic_mb           313168 non-null  float64\n",
      " 3   avg_rrc_connected_user  313186 non-null  float64\n",
      " 4   prb_dl_used             312997 non-null  float64\n",
      " 5   prb_dl_available_total  312997 non-null  float64\n",
      " 6   prb_utilization         313186 non-null  float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 19.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 2 (train.ipynb - SỬA LỖI CHO CSV): Tải dữ liệu đã xử lý ---\n",
    "file_name = 'kpi_processed.csv' # <-- Đã đổi tên file\n",
    "try:\n",
    "    # *** THAY ĐỔI QUAN TRỌNG ***\n",
    "    # Chúng ta dùng pd.read_csv và thêm 2 tham số:\n",
    "    # 1. index_col=0: Báo cho Pandas rằng cột đầu tiên (cột 0) là index.\n",
    "    # 2. parse_dates=True: Báo cho Pandas chuyển đổi index đó thành Datetime.\n",
    "    df = pd.read_csv(file_name, index_col=0, parse_dates=True)\n",
    "    \n",
    "    print(f\"Tải file '{file_name}' thành công.\")\n",
    "    print(f\"Dữ liệu có {len(df)} hàng, kéo dài từ {df.index.min()} đến {df.index.max()}.\")\n",
    "    print(\"\\nThông tin dữ liệu (df.info()):\")\n",
    "    df.info() \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"LỖI: Không thể tải file '{file_name}'.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3eeffa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự đoán 5 features: ['ps_traffic_mb', 'avg_rrc_connected_user', 'prb_dl_used', 'prb_dl_available_total', 'prb_utilization']\n",
      "Đang xử lý: Đảm bảo dữ liệu 15 phút đầy đủ cho mỗi cell...\n",
      "Dữ liệu trước khi xử lý trùng lặp: 313186 hàng\n",
      "Dữ liệu sau khi xử lý trùng lặp (groupby.mean): 303370 hàng\n",
      "Dữ liệu gốc có 313186 hàng.\n",
      "Dữ liệu đã điền đầy đủ (sau reindex) có 321408 hàng.\n",
      "Hoàn tất xử lý.\n",
      "\n",
      "5 dòng đầu của dữ liệu đã xử lý đầy đủ:\n",
      "                    cell_name  ps_traffic_mb  avg_rrc_connected_user  \\\n",
      "timestamp                                                              \n",
      "2025-10-11 00:00:00  EnodebA3         161.14                8.527778   \n",
      "2025-10-11 00:15:00  EnodebA3           0.00                0.000000   \n",
      "2025-10-11 00:30:00  EnodebA3           0.00                0.000000   \n",
      "2025-10-11 00:45:00  EnodebA3           0.00                0.000000   \n",
      "2025-10-11 01:00:00  EnodebA3         231.61                7.777778   \n",
      "\n",
      "                     prb_dl_used  prb_dl_available_total  prb_utilization  \n",
      "timestamp                                                                  \n",
      "2025-10-11 00:00:00         67.5                    15.0            450.0  \n",
      "2025-10-11 00:15:00          0.0                     0.0              0.0  \n",
      "2025-10-11 00:30:00          0.0                     0.0              0.0  \n",
      "2025-10-11 00:45:00          0.0                     0.0              0.0  \n",
      "2025-10-11 01:00:00         67.5                    15.0            450.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Cell 3: Xử lý dữ liệu (Quan trọng!) ---\n",
    "# Mục tiêu: Đảm bảo MỌI cell_name đều có đầy đủ 15 phút, không bị ngắt quãng.\n",
    "# Nếu thiếu, chúng ta sẽ lấp đầy bằng 0.\n",
    "if 'df' in locals():\n",
    "    # Xác định các cột KPI để dự đoán\n",
    "    FEATURE_COLS = ['ps_traffic_mb', 'avg_rrc_connected_user', 'prb_dl_used', 'prb_dl_available_total', 'prb_utilization']\n",
    "    N_FEATURES = len(FEATURE_COLS)\n",
    "    print(f\"Dự đoán {N_FEATURES} features: {FEATURE_COLS}\")\n",
    "    # Tạo ra một DataFrame đầy đủ cho MỌI cell\n",
    "    print(\"Đang xử lý: Đảm bảo dữ liệu 15 phút đầy đủ cho mỗi cell...\")\n",
    "    # Lấy tất cả các cell độc nhất\n",
    "    all_cells = df['cell_name'].unique()\n",
    "    # Tạo ra một index thời gian 15 phút đầy đủ từ đầu đến cuối\n",
    "    # (Sửa lỗi cảnh báo: '15T' -> '15min')\n",
    "    full_time_index = pd.date_range(start=df.index.min(), end=df.index.max(), freq='15min')\n",
    "    # Tạo MultiIndex (cell_name, timestamp)\n",
    "    multi_index = pd.MultiIndex.from_product([all_cells, full_time_index], names=['cell_name', 'timestamp'])\n",
    "    # Lấy các cột dữ liệu\n",
    "    df_data_only = df[FEATURE_COLS + ['cell_name']]\n",
    "    # Đưa timestamp ra thành một cột\n",
    "    df_data_only = df_data_only.reset_index()\n",
    "    # Xử lý các (cell_name, timestamp) bị trùng lặp\n",
    "    print(f\"Dữ liệu trước khi xử lý trùng lặp: {len(df_data_only)} hàng\")\n",
    "    df_grouped_unique = df_data_only.groupby(['cell_name', 'timestamp']).mean()\n",
    "    print(f\"Dữ liệu sau khi xử lý trùng lặp (groupby.mean): {len(df_grouped_unique)} hàng\")\n",
    "    # Reindex với MultiIndex đầy đủ, điền 0 vào các chỗ thiếu\n",
    "    df_full = df_grouped_unique.reindex(multi_index, fill_value=0)\n",
    "    # *** (BƯỚC SỬA LỖI KEYERROR) ***\n",
    "    # 1. Reset TẤT CẢ các cấp index ('cell_name', 'timestamp') ra thành cột\n",
    "    df_full = df_full.reset_index() \n",
    "    # 2. Đặt cột 'timestamp' làm index mới.\n",
    "    # 'cell_name' bây giờ sẽ tự động là một cột, chính xác như chúng ta muốn.\n",
    "    df_full = df_full.set_index('timestamp')\n",
    "    # *** (KẾT THÚC SỬA LỖI) ***\n",
    "    print(f\"Dữ liệu gốc có {len(df)} hàng.\")\n",
    "    print(f\"Dữ liệu đã điền đầy đủ (sau reindex) có {len(df_full)} hàng.\")\n",
    "    print(\"Hoàn tất xử lý.\")\n",
    "    print(\"\\n5 dòng đầu của dữ liệu đã xử lý đầy đủ:\")\n",
    "    print(df_full.head())\n",
    "else:\n",
    "    print(\"Lỗi: DataFrame 'df' không tồn tại. Vui lòng chạy lại Cell 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c50e765d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cấu hình mô hình: Input 192 bước (2 ngày), Output 96 bước (1 ngày).\n",
      "Yêu cầu dữ liệu tối thiểu cho 1 mẫu: 276 bước (28 ngày)\n",
      "\n",
      "Mốc Train (70%):  Kết thúc lúc 2025-11-01 16:37:30\n",
      "Mốc Val (20%):    Kết thúc lúc 2025-11-07 21:22:30 (Bắt đầu từ 2025-11-01 16:37:30)\n",
      "Mốc Test (10%):   Bắt đầu từ  2025-11-07 21:22:30\n",
      "\n",
      "Kích thước tập Train: (224964, 6)\n",
      "Kích thước tập Val:   (64260, 6)\n",
      "Kích thước tập Test:  (32184, 6)\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: \n",
    "# Data của chúng ta có tần suất 15 phút (4 mẫu/giờ)\n",
    "TIMESTEPS_PER_HOUR = 4\n",
    "TIMESTEPS_PER_DAY = 24 * TIMESTEPS_PER_HOUR # 96\n",
    "# (THAY ĐỔI QUAN TRỌNG TẠI ĐÂY) \n",
    "# Input: 2 ngày\n",
    "INPUT_DAYS = 2\n",
    "INPUT_STEPS = INPUT_DAYS * TIMESTEPS_PER_DAY # 2 * 96 = 192\n",
    "# Output: 1 ngày\n",
    "OUTPUT_DAYS = 1\n",
    "OUTPUT_STEPS = OUTPUT_DAYS * TIMESTEPS_PER_DAY # 1 * 96 = 96\n",
    "# *** (KẾT THÚC THAY ĐỔI) ***\n",
    "\n",
    "# Yêu cầu dữ liệu tối thiểu = 192 + 96 = 276 steps (28 ngày)\n",
    "print(f\"Cấu hình mô hình: Input {INPUT_STEPS} bước (2 ngày), Output {OUTPUT_STEPS} bước (1 ngày).\")\n",
    "print(f\"Yêu cầu dữ liệu tối thiểu cho 1 mẫu: 276 bước (28 ngày)\")\n",
    "\n",
    "# TÁCH DỮ LIỆU THEO THỜI GIAN (70/20/10)\n",
    "if 'df_full' in locals():\n",
    "    total_duration = df_full.index.max() - df_full.index.min()\n",
    "    \n",
    "    # 70% cho Train\n",
    "    train_end_time = df_full.index.min() + total_duration * 0.7\n",
    "    \n",
    "    # Thêm 20% cho Validation (tổng 90%)\n",
    "    val_end_time = df_full.index.min() + total_duration * 0.9\n",
    "    \n",
    "    # 10% còn lại cho Test\n",
    "\n",
    "    print(f\"\\nMốc Train (70%):  Kết thúc lúc {train_end_time}\")\n",
    "    print(f\"Mốc Val (20%):    Kết thúc lúc {val_end_time} (Bắt đầu từ {train_end_time})\")\n",
    "    print(f\"Mốc Test (10%):   Bắt đầu từ  {val_end_time}\")\n",
    "\n",
    "    # Tách\n",
    "    train_df = df_full[df_full.index < train_end_time]\n",
    "    val_df = df_full[(df_full.index >= train_end_time) & (df_full.index < val_end_time)]\n",
    "    test_df = df_full[df_full.index >= val_end_time]\n",
    "    \n",
    "    print(f\"\\nKích thước tập Train: {train_df.shape}\")\n",
    "    print(f\"Kích thước tập Val:   {val_df.shape}\")\n",
    "    print(f\"Kích thước tập Test:  {test_df.shape}\")\n",
    "else:\n",
    "    print(\"Lỗi: DataFrame 'df_full' không tồn tại. Vui lòng chạy lại Cell 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd77b53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiểm tra dữ liệu bẩn:\n",
      "Số lượng NaN: 145\n",
      "Số lượng Inf: 0\n",
      "Đã làm sạch dữ liệu NaN/Inf.\n",
      "Hoàn tất scaling dữ liệu.\n",
      "Dữ liệu train sau khi scale (5 dòng đầu):\n",
      "                     ps_traffic_mb  avg_rrc_connected_user  prb_dl_used  \\\n",
      "timestamp                                                                 \n",
      "2025-10-11 00:00:00       0.015048                0.020689     0.047368   \n",
      "2025-10-11 00:15:00       0.000000                0.000000     0.000000   \n",
      "2025-10-11 00:30:00       0.000000                0.000000     0.000000   \n",
      "2025-10-11 00:45:00       0.000000                0.000000     0.000000   \n",
      "2025-10-11 01:00:00       0.021629                0.018869     0.047368   \n",
      "\n",
      "                     prb_dl_available_total  prb_utilization cell_name  \n",
      "timestamp                                                               \n",
      "2025-10-11 00:00:00                  0.9375         0.047368  EnodebA3  \n",
      "2025-10-11 00:15:00                  0.0000         0.000000  EnodebA3  \n",
      "2025-10-11 00:30:00                  0.0000         0.000000  EnodebA3  \n",
      "2025-10-11 00:45:00                  0.0000         0.000000  EnodebA3  \n",
      "2025-10-11 01:00:00                  0.9375         0.047368  EnodebA3  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Cell 5: Chuẩn hóa (Scaling) Dữ liệu ---\n",
    "# Chúng ta phải fit Scaler CHỈ trên dữ liệu train để tránh rò rỉ dữ liệu\n",
    "\n",
    "# Kiểm tra xem có NaN hay Inf trong train_df không\n",
    "print(\"Kiểm tra dữ liệu bẩn:\")\n",
    "print(\"Số lượng NaN:\", train_df.isna().sum().sum())\n",
    "print(\"Số lượng Inf:\", np.isinf(train_df[FEATURE_COLS].values).sum())\n",
    "\n",
    "# Xử lý thay thế (nếu có)\n",
    "train_df = train_df.replace([np.inf, -np.inf], 0)\n",
    "train_df = train_df.fillna(0)\n",
    "\n",
    "val_df = val_df.replace([np.inf, -np.inf], 0)\n",
    "val_df = val_df.fillna(0)\n",
    "\n",
    "test_df = test_df.replace([np.inf, -np.inf], 0)\n",
    "test_df = test_df.fillna(0)\n",
    "\n",
    "print(\"Đã làm sạch dữ liệu NaN/Inf.\")\n",
    "if 'train_df' in locals():\n",
    "    # Khởi tạo Scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # 1. Fit scaler CHỈ trên dữ liệu train (chỉ các cột features)\n",
    "    # Chúng ta phải fit trên toàn bộ dữ liệu train để scaler học được min/max\n",
    "    scaler.fit(train_df[FEATURE_COLS])\n",
    "    \n",
    "    # 2. Transform cả 3 tập\n",
    "    # Lưu lại 'cell_name' để dùng cho việc nhóm\n",
    "    train_cells = train_df['cell_name']\n",
    "    val_cells = val_df['cell_name']\n",
    "    test_cells = test_df['cell_name']\n",
    "\n",
    "    # Transform\n",
    "    train_scaled_data = scaler.transform(train_df[FEATURE_COLS])\n",
    "    val_scaled_data = scaler.transform(val_df[FEATURE_COLS])\n",
    "    test_scaled_data = scaler.transform(test_df[FEATURE_COLS])\n",
    "    \n",
    "    # 3. Tạo lại DataFrame đã scale (việc này giúp nhóm dễ dàng hơn)\n",
    "    scaled_train_df = pd.DataFrame(train_scaled_data, columns=FEATURE_COLS, index=train_df.index)\n",
    "    scaled_train_df['cell_name'] = train_cells\n",
    "\n",
    "    scaled_val_df = pd.DataFrame(val_scaled_data, columns=FEATURE_COLS, index=val_df.index)\n",
    "    scaled_val_df['cell_name'] = val_cells\n",
    "\n",
    "    scaled_test_df = pd.DataFrame(test_scaled_data, columns=FEATURE_COLS, index=test_df.index)\n",
    "    scaled_test_df['cell_name'] = test_cells\n",
    "    \n",
    "    print(\"Hoàn tất scaling dữ liệu.\")\n",
    "    print(\"Dữ liệu train sau khi scale (5 dòng đầu):\")\n",
    "    print(scaled_train_df.head())\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b38121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Cell 6: Hàm tạo cửa sổ (Windowing) ---\n",
    "# Đây là hàm quan trọng nhất:\n",
    "# Nó sẽ duyệt qua TỪNG cell_name, sau đó tạo các cặp (X, y)\n",
    "# X = 672 bước (7 ngày), y = 96 bước (1 ngày)\n",
    "\n",
    "def create_windows(data_df, input_steps, output_steps, feature_cols):\n",
    "    \"\"\"\n",
    "    Tạo các cửa sổ X (input) và y (output) từ dữ liệu đã scale,\n",
    "    nhóm theo 'cell_name'.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Nhóm dữ liệu theo từng cell\n",
    "    grouped = data_df.groupby('cell_name')\n",
    "    \n",
    "    total_cells = len(grouped)\n",
    "    print(f\"Bắt đầu tạo cửa sổ cho {total_cells} cell...\")\n",
    "    \n",
    "    cell_count = 0\n",
    "    for cell_id, cell_data in grouped:\n",
    "        cell_count += 1\n",
    "        if cell_count % 50 == 0:\n",
    "            print(f\"  ...đang xử lý cell {cell_count}/{total_cells} (ID: {cell_id})\")\n",
    "            \n",
    "        # Lấy dữ liệu số của cell này\n",
    "        cell_features = cell_data[feature_cols].values\n",
    "        \n",
    "        # Tổng số mẫu của cell này\n",
    "        total_samples = len(cell_features)\n",
    "        \n",
    "        # Tổng độ dài cần thiết cho 1 cửa sổ\n",
    "        total_window_len = input_steps + output_steps\n",
    "        \n",
    "        # Trượt cửa sổ\n",
    "        for i in range(total_samples - total_window_len + 1):\n",
    "            # i là điểm bắt đầu của input\n",
    "            input_start = i\n",
    "            input_end = i + input_steps\n",
    "            \n",
    "            # output_end là điểm kết thúc của output\n",
    "            output_end = input_end + output_steps\n",
    "            \n",
    "            # Lấy cửa sổ X và y\n",
    "            window_X = cell_features[input_start:input_end, :]\n",
    "            window_y = cell_features[input_end:output_end, :]\n",
    "            \n",
    "            X.append(window_X)\n",
    "            y.append(window_y)\n",
    "            \n",
    "    print(f\"Hoàn tất tạo cửa sổ. Đã tạo {len(X)} mẫu.\")\n",
    "    \n",
    "    # Chuyển list thành Numpy array\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb7a3660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Đang tạo mẫu Train (X_train, y_train) ---\n",
      "Bắt đầu tạo cửa sổ cho 108 cell...\n",
      "  ...đang xử lý cell 50/108 (ID: EnodebE2)\n",
      "  ...đang xử lý cell 100/108 (ID: EnodebK1)\n",
      "Hoàn tất tạo cửa sổ. Đã tạo 193968 mẫu.\n",
      "\n",
      "--- Đang tạo mẫu Validation (X_val, y_val) ---\n",
      "Bắt đầu tạo cửa sổ cho 108 cell...\n",
      "  ...đang xử lý cell 50/108 (ID: EnodebE2)\n",
      "  ...đang xử lý cell 100/108 (ID: EnodebK1)\n",
      "Hoàn tất tạo cửa sổ. Đã tạo 33264 mẫu.\n",
      "\n",
      "--- Đang tạo mẫu Test (X_test, y_test) ---\n",
      "Bắt đầu tạo cửa sổ cho 108 cell...\n",
      "  ...đang xử lý cell 50/108 (ID: EnodebE2)\n",
      "  ...đang xử lý cell 100/108 (ID: EnodebK1)\n",
      "Hoàn tất tạo cửa sổ. Đã tạo 1188 mẫu.\n",
      "\n",
      "--- Kích thước dữ liệu (Shape) ---\n",
      "X_train shape: (193968, 192, 5)\n",
      "y_train shape: (193968, 96, 5)\n",
      "X_val shape:   (33264, 192, 5)\n",
      "y_val shape:   (33264, 96, 5)\n",
      "X_test shape:  (1188, 192, 5)\n",
      "y_test shape:  (1188, 96, 5)\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 7: Áp dụng hàm Windowing ---\n",
    "\n",
    "if 'scaled_train_df' in locals():\n",
    "    print(\"--- Đang tạo mẫu Train (X_train, y_train) ---\")\n",
    "    X_train, y_train = create_windows(scaled_train_df, INPUT_STEPS, OUTPUT_STEPS, FEATURE_COLS)\n",
    "    \n",
    "    print(\"\\n--- Đang tạo mẫu Validation (X_val, y_val) ---\")\n",
    "    X_val, y_val = create_windows(scaled_val_df, INPUT_STEPS, OUTPUT_STEPS, FEATURE_COLS)\n",
    "    \n",
    "    print(\"\\n--- Đang tạo mẫu Test (X_test, y_test) ---\")\n",
    "    X_test, y_test = create_windows(scaled_test_df, INPUT_STEPS, OUTPUT_STEPS, FEATURE_COLS)\n",
    "    \n",
    "    print(\"\\n--- Kích thước dữ liệu (Shape) ---\")\n",
    "    print(f\"X_train shape: {X_train.shape}\") # (Số mẫu, 672, N_FEATURES)\n",
    "    print(f\"y_train shape: {y_train.shape}\") # (Số mẫu, 96, N_FEATURES)\n",
    "    print(f\"X_val shape:   {X_val.shape}\")\n",
    "    print(f\"y_val shape:   {y_val.shape}\")\n",
    "    print(f\"X_test shape:  {X_test.shape}\")\n",
    "    print(f\"y_test shape:  {y_test.shape}\")\n",
    "else:\n",
    "    print(\"Lỗi: Dữ liệu đã scale không tồn tại. Vui lòng chạy lại Cell 5.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "639623ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">505</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m42,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m80,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m5\u001b[0m)          │           \u001b[38;5;34m505\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,305</span> (481.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m123,305\u001b[0m (481.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,305</span> (481.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m123,305\u001b[0m (481.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Cell 8 (Cập nhật): Xây dựng mô hình LSTM (Seq2Seq) ---\n",
    "# Cập nhật Input (2016 steps) và Output (672 steps)\n",
    "# --- SỬA LẠI CELL 8 ---\n",
    "if 'X_train' in locals() and X_train.shape[0] > 0:\n",
    "    keras.backend.clear_session()\n",
    "    N_UNITS_LSTM = 100 \n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input\n",
    "    model.add(Input(shape=(INPUT_STEPS, N_FEATURES)))\n",
    "    \n",
    "    # Encoder: ĐỔI 'relu' THÀNH 'tanh'\n",
    "    model.add(LSTM(N_UNITS_LSTM, activation='tanh')) \n",
    "    \n",
    "    # Repeater\n",
    "    model.add(RepeatVector(OUTPUT_STEPS))\n",
    "    \n",
    "    # Decoder: ĐỔI 'relu' THÀNH 'tanh'\n",
    "    model.add(LSTM(N_UNITS_LSTM, activation='tanh', return_sequences=True))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(TimeDistributed(Dense(N_FEATURES)))\n",
    "    \n",
    "    # --- QUAN TRỌNG: Cấu hình Optimizer để kẹp Gradient (Clipnorm) ---\n",
    "    # Nếu gradient vẫn quá lớn, clipnorm sẽ cắt bớt nó lại\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    \n",
    "else:\n",
    "    print(\"Lỗi: Không có dữ liệu training (X_train) để xây dựng mô hình.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007b42f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu huấn luyện (training) mô hình...\n",
      "Epoch 1/20\n",
      "\u001b[1m3031/3031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2076s\u001b[0m 680ms/step - loss: 0.0154 - mae: 0.0556 - val_loss: 0.0098 - val_mae: 0.0407\n",
      "Epoch 2/20\n",
      "\u001b[1m1123/3031\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m23:32\u001b[0m 740ms/step - loss: 0.0117 - mae: 0.0453"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# --- Cell 9: Huấn luyện mô hình ---\n",
    "\n",
    "if 'model' in locals():\n",
    "    print(\"Bắt đầu huấn luyện (training) mô hình...\")\n",
    "    \n",
    "    # Hằng số huấn luyện\n",
    "    EPOCHS = 20 # Số lượt học (tăng lên 50-100 nếu có GPU)\n",
    "    BATCH_SIZE = 64 # Số mẫu học trong 1 lần\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[\n",
    "            # Dừng sớm nếu val_loss không cải thiện\n",
    "            keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"Hoàn tất huấn luyện!\")\n",
    "    \n",
    "    # Lưu mô hình (tùy chọn)\n",
    "    # model.save('kpi_lstm_model.h5')\n",
    "    # print(\"Đã lưu mô hình vào 'kpi_lstm_model.h5'\")\n",
    "\n",
    "else:\n",
    "    print(\"Lỗi: Mô hình chưa được định nghĩa.\")\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e0a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Cell 10: Đánh giá Loss và \"Accuracy\" ---\n",
    "\n",
    "if 'history' in locals():\n",
    "    print(\"--- Đánh giá kết quả huấn luyện ---\")\n",
    "\n",
    "    # 1. Trực quan hóa Loss (MSE) và MAE\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    \n",
    "    # Plot Loss (MSE)\n",
    "    ax1.plot(history.history['loss'], label='Train Loss (MSE)')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss (MSE)')\n",
    "    ax1.set_title('Model Loss (Mean Squared Error)')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss (MSE)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot \"Accuracy\" (Chúng ta dùng MAE - Mean Absolute Error)\n",
    "    # GHI CHÚ: \"Accuracy\" là metric cho bài toán Phân loại (Classification).\n",
    "    # Đối với bài toán Hồi quy (Regression) như dự đoán KPI, \n",
    "    # chúng ta dùng MAE để đo \"độ chính xác\" (sai số tuyệt đối trung bình).\n",
    "    \n",
    "    ax2.plot(history.history['mae'], label='Train MAE')\n",
    "    ax2.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    ax2.set_title('Model \"Accuracy\" (Mean Absolute Error)')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Mean Absolute Error (MAE)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # 2. Đánh giá trên tập TEST (Dữ liệu chưa từng thấy)\n",
    "    print(\"\\n--- Đánh giá trên tập Test ---\")\n",
    "    # model.evaluate sẽ trả về [loss, metric_1, metric_2, ...]\n",
    "    # Tương ứng với compile(loss='mse', metrics=['mae'])\n",
    "    test_results = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    test_loss_mse = test_results[0]\n",
    "    test_metric_mae = test_results[1]\n",
    "\n",
    "    print(f\"  Test Loss (MSE): {test_loss_mse:.6f}\")\n",
    "    print(f\"  Test MAE (Mean Absolute Error): {test_metric_mae:.6f}\")\n",
    "    \n",
    "    print(\"\\nGiải thích MAE:\")\n",
    "    print(f\"Giá trị MAE = {test_metric_mae:.6f} (trên dữ liệu đã scale từ 0-1).\")\n",
    "    print(\"Điều này có nghĩa là, trên thang 0-1, dự đoán của mô hình\")\n",
    "    print(f\"sai lệch trung bình khoảng {test_metric_mae:.6f} so với giá trị thực tế.\")\n",
    "    print(\"(Để có MAE theo đơn vị gốc (MB, Users...), chúng ta cần dùng scaler.inverse_transform)\")\n",
    "    \n",
    "else:\n",
    "    print(\"Lỗi: Biến 'history' không tồn tại. Mô hình chưa được huấn luyện.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f42b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 11: So sánh kết quả dự đoán với giá trị thực tế ---\n",
    "\n",
    "if 'model' in locals() and 'X_test' in locals() and 'y_test' in locals() and 'scaler' in locals():\n",
    "    print(\"--- Trực quan hóa kết quả dự đoán trên tập Test ---\")\n",
    "\n",
    "    # 1. Dự đoán trên tập Test\n",
    "    # Chọn một batch từ X_test để dự đoán\n",
    "    # (Để đơn giản, ta lấy một vài mẫu đầu tiên hoặc một mẫu ngẫu nhiên)\n",
    "    num_samples_to_plot = min(5, X_test.shape[0]) # Vẽ 5 mẫu hoặc ít hơn nếu X_test ít hơn\n",
    "\n",
    "    if num_samples_to_plot == 0:\n",
    "        print(\"Không có mẫu nào trong X_test để dự đoán và trực quan hóa.\")\n",
    "    else:\n",
    "        # Lấy các mẫu đầu tiên từ X_test và y_test\n",
    "        X_test_subset = X_test[:num_samples_to_plot]\n",
    "        y_test_subset = y_test[:num_samples_to_plot]\n",
    "\n",
    "        # Thực hiện dự đoán\n",
    "        y_pred_scaled = model.predict(X_test_subset)\n",
    "\n",
    "        # Đảo ngược quá trình chuẩn hóa (Inverse Scaling) cho cả giá trị thực và dự đoán\n",
    "        # Chúng ta cần reshape lại dữ liệu thành 2D trước khi inverse_transform\n",
    "        \n",
    "        # Reshape y_test_subset (batch_size, output_steps, n_features) -> (batch_size * output_steps, n_features)\n",
    "        y_true_reshaped = y_test_subset.reshape(-1, N_FEATURES)\n",
    "        y_true_original = scaler.inverse_transform(y_true_reshaped)\n",
    "        y_true_original = y_true_original.reshape(num_samples_to_plot, OUTPUT_STEPS, N_FEATURES)\n",
    "\n",
    "        # Reshape y_pred_scaled (batch_size, output_steps, n_features) -> (batch_size * output_steps, n_features)\n",
    "        y_pred_reshaped = y_pred_scaled.reshape(-1, N_FEATURES)\n",
    "        y_pred_original = scaler.inverse_transform(y_pred_reshaped)\n",
    "        y_pred_original = y_pred_original.reshape(num_samples_to_plot, OUTPUT_STEPS, N_FEATURES)\n",
    "\n",
    "        # 2. Vẽ biểu đồ so sánh cho từng mẫu\n",
    "        for i in range(num_samples_to_plot):\n",
    "            print(f\"\\n--- So sánh Mẫu #{i+1} ---\")\n",
    "            \n",
    "            fig, axes = plt.subplots(N_FEATURES, 1, figsize=(15, 5 * N_FEATURES), sharex=True)\n",
    "            if N_FEATURES == 1: # Xử lý trường hợp chỉ có 1 feature (axes sẽ không phải mảng)\n",
    "                axes = [axes]\n",
    "\n",
    "            for j, feature_name in enumerate(FEATURE_COLS):\n",
    "                ax = axes[j]\n",
    "                ax.plot(y_true_original[i, :, j], label=f'Thực tế ({feature_name})', color='blue', marker='o', linestyle='-')\n",
    "                ax.plot(y_pred_original[i, :, j], label=f'Dự đoán ({feature_name})', color='red', marker='x', linestyle='--')\n",
    "                ax.set_title(f'Dự đoán {feature_name} (Mẫu #{i+1})')\n",
    "                ax.set_xlabel('Bước thời gian (15 phút)')\n",
    "                ax.set_ylabel(f'Giá trị {feature_name}')\n",
    "                ax.legend()\n",
    "                ax.grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        print(\"\\nHoàn tất trực quan hóa.\")\n",
    "\n",
    "else:\n",
    "    print(\"Lỗi: Không thể trực quan hóa. Đảm bảo 'model', 'X_test', 'y_test', 'scaler' đã tồn tại và X_test không rỗng.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
