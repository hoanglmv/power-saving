{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Optional LightGBM\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGB = True\n",
    "    print(\"Using LightGBM\")\n",
    "except Exception:\n",
    "    LGB = False\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    print(\"LightGBM not installed → Using RandomForest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_parse_date_hour(s):\n",
    "    try:\n",
    "        return pd.to_datetime(s, format='%Y-%m-%d-%H')\n",
    "    except Exception:\n",
    "        try:\n",
    "            return pd.to_datetime(s, errors='coerce')\n",
    "        except Exception:\n",
    "            return pd.NaT\n",
    "\n",
    "\n",
    "def load_and_prepare(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    df['date_hour_dt'] = df['date_hour'].astype(str).apply(robust_parse_date_hour)\n",
    "    df = df.dropna(subset=['date_hour_dt'])\n",
    "\n",
    "    kpi_cols = ['ps_traffic_mb', 'avg_rrc_connected_user', 'prb_dl_used', 'prb_dl_available_total']\n",
    "    for c in kpi_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    df = df.dropna(subset=['cell_name'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c34be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_weekly(df):\n",
    "    df['week_start'] = df['date_hour_dt'].dt.to_period('W').apply(lambda p: p.start_time)\n",
    "\n",
    "    agg_funcs = {\n",
    "        'ps_traffic_mb': ['sum', 'mean', 'max', 'std'],\n",
    "        'avg_rrc_connected_user': ['mean', 'max'],\n",
    "        'prb_dl_used': ['mean', 'max'],\n",
    "        'prb_dl_available_total': ['mean']\n",
    "    }\n",
    "\n",
    "    weekly = df.groupby(['cell_name', 'enodeb', 'week_start']).agg(agg_funcs)\n",
    "    weekly.columns = ['_'.join(col).strip() for col in weekly.columns.values]\n",
    "    weekly = weekly.reset_index().fillna(0)\n",
    "\n",
    "    if 'ps_traffic_mb_sum' in weekly.columns:\n",
    "        weekly = weekly.rename(columns={'ps_traffic_mb_sum': 'weekly_ps_traffic'})\n",
    "    else:\n",
    "        weekly['weekly_ps_traffic'] = 0.0\n",
    "\n",
    "    return weekly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_features(weekly, weeks_lag=3):\n",
    "    weekly = weekly.sort_values(['cell_name', 'week_start']).copy()\n",
    "    \n",
    "    numeric_base = [\n",
    "        'weekly_ps_traffic', 'ps_traffic_mb_mean', 'ps_traffic_mb_max',\n",
    "        'avg_rrc_connected_user_mean', 'prb_dl_used_mean', 'prb_dl_available_total_mean'\n",
    "    ]\n",
    "\n",
    "    for lag in range(1, weeks_lag + 1):\n",
    "        for c in numeric_base:\n",
    "            if c in weekly.columns:\n",
    "                weekly[f'{c}_lag{lag}'] = weekly.groupby('cell_name')[c].shift(lag)\n",
    "\n",
    "    lag1 = 'weekly_ps_traffic_lag1'\n",
    "    lagN = f'weekly_ps_traffic_lag{weeks_lag}'\n",
    "    if lag1 in weekly.columns and lagN in weekly.columns:\n",
    "        weekly[f'weekly_traffic_trend_{weeks_lag}w'] = \\\n",
    "            (weekly[lag1] - weekly[lagN]) / float(weeks_lag)\n",
    "\n",
    "    required = [f'weekly_ps_traffic_lag{l}' for l in range(1, weeks_lag + 1)]\n",
    "    weekly = weekly.dropna(subset=required)\n",
    "\n",
    "    return weekly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7527d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2466c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target_next_week(weekly):\n",
    "    weekly = weekly.sort_values(['cell_name', 'week_start']).copy()\n",
    "    weekly['target_weekly_ps_traffic'] = weekly.groupby('cell_name')['weekly_ps_traffic'].shift(-1)\n",
    "    return weekly.dropna(subset=['target_weekly_ps_traffic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329636cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(weekly):\n",
    "    weekly = pd.get_dummies(weekly, columns=['enodeb'], drop_first=True)\n",
    "\n",
    "    feat_cols = [\n",
    "        c for c in weekly.columns \n",
    "        if ('_lag' in c)\n",
    "        or c.startswith('enodeb_')\n",
    "        or c in ['ps_traffic_mb_mean', 'avg_rrc_connected_user_mean', 'prb_dl_used_mean']\n",
    "    ]\n",
    "\n",
    "    X = weekly[feat_cols].fillna(0)\n",
    "    y = weekly['target_weekly_ps_traffic']\n",
    "\n",
    "    return weekly, X, y, feat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d9b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_based_split(weekly, test_ratio=0.15):\n",
    "    weeks = sorted(weekly['week_start'].unique())\n",
    "    n_test = max(1, int(len(weeks) * test_ratio))\n",
    "    test_start = weeks[-n_test]\n",
    "\n",
    "    train_mask = weekly['week_start'] < test_start\n",
    "    test_mask  = weekly['week_start'] >= test_start\n",
    "\n",
    "    return train_mask, test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0eb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, y_train, X_test, y_test):\n",
    "    # đảm bảo y là số\n",
    "    y_train = np.asarray(y_train).astype(float)\n",
    "    y_test  = np.asarray(y_test).astype(float)\n",
    "\n",
    "    if LGB:\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mae',\n",
    "            'learning_rate': 0.05,\n",
    "            'num_leaves': 31,\n",
    "            'verbose': -1\n",
    "        }\n",
    "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "        model = lgb.train(params, dtrain, num_boost_round=500)\n",
    "        y_pred = model.predict(X_test)\n",
    "        fi = pd.Series(model.feature_importance(), index=X_train.columns)\n",
    "    else:\n",
    "        rf = RandomForestRegressor(n_estimators=200, max_depth=12, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        model = rf\n",
    "        fi = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)        # trả về MSE (không dùng tham số squared)\n",
    "    rmse = np.sqrt(mse)                             # convert MSE -> RMSE\n",
    "    # MAPE: tránh chia cho 0\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        mape = np.abs((y_test - y_pred) / np.where(y_test==0, np.nan, y_test))\n",
    "        mape = np.nanmean(mape) * 100\n",
    "\n",
    "    return model, y_pred, {'mae': mae, 'rmse': rmse, 'mape': mape}, fi.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"D:\\\\vhproj\\\\power-saving\\\\data\\\\kpi_15_mins.csv\"\n",
    "\n",
    "df = load_and_prepare(csv_path)\n",
    "print(\"Loaded rows:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly = aggregate_weekly(df)\n",
    "print(\"Weekly rows:\", len(weekly))\n",
    "weekly.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly = create_lag_features(weekly, weeks_lag=3)\n",
    "weekly = make_target_next_week(weekly)\n",
    "\n",
    "print(\"Rows after lag + target:\", len(weekly))\n",
    "weekly.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319993a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly, X_all, y_all, feat_cols = prepare_features(weekly)\n",
    "len(X_all), len(feat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad233e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, test_mask = time_based_split(weekly, test_ratio=0.15)\n",
    "\n",
    "X_train, y_train = X_all[train_mask], y_all[train_mask]\n",
    "X_test, y_test   = X_all[test_mask], y_all[test_mask]\n",
    "\n",
    "print(\"Train size:\", len(X_train), \"Test size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ea44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_pred, metrics, fi = train_and_evaluate(X_train, y_train, X_test, y_test)\n",
    "\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995f7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65600a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_week = weekly['week_start'].max()\n",
    "latest_df = weekly[weekly['week_start'] == latest_week]\n",
    "\n",
    "X_latest = latest_df[feat_cols].fillna(0)\n",
    "pred_next = model.predict(X_latest)\n",
    "\n",
    "final_next = latest_df[['cell_name', 'week_start']].copy()\n",
    "final_next['pred_next_week'] = pred_next\n",
    "\n",
    "final_next.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"forecast_output\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "weekly[test_mask].assign(pred=y_pred).to_csv(f\"{out_dir}/test_predictions.csv\", index=False)\n",
    "final_next.to_csv(f\"{out_dir}/pred_next_week.csv\", index=False)\n",
    "\n",
    "print(\"Saved to:\", out_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
